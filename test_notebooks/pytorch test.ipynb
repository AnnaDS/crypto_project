{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for training\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "# import dataset, network to train and metric to optimize\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv('./data/ETH_histical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data.date=pd.DatetimeIndex(data.date)\n",
    "data['date_seconds']=data.date.astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['crypto']='ETH'\n",
    "data.fillna(mathod='ffill', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python3_env/lib/python3.7/site-packages/pytorch_forecasting/data/timeseries.py:1244: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 1 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__crypto': 'ETH'}]\n",
      "  UserWarning,\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fb12f0e2689d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#time_varying_unknown_categoricals=[ 'volume' ],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtime_varying_unknown_reals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mallow_missing_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_env/lib/python3.7/site-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# create index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# convert to torch tensor for high performance data loading later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_env/lib/python3.7/site-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m_construct_index\u001b[0;34m(self, data, predict_mode)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         assert (\n\u001b[1;32m   1247\u001b[0m             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m         ), \"filters should not remove entries all entries - check encoder/decoder lengths and lags\"\n\u001b[0m\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
     ]
    }
   ],
   "source": [
    "# define the dataset, i.e. add metadata to pandas dataframe for the model to understand it\n",
    "max_encoder_length = 36\n",
    "max_prediction_length = 6\n",
    "training_cutoff = \"2021-06-01\"  # day for cutoff\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.date <= training_cutoff],\n",
    "    time_idx= 'date_seconds',  # column name of time of observation\n",
    "    target='close',  # column name of target to predict\n",
    "    group_ids=[ 'crypto' ],  # column name(s) for timeseries IDs\n",
    "    max_encoder_length=max_encoder_length,  # how much history to use\n",
    "    max_prediction_length=max_prediction_length,  # how far to predict into future\n",
    "    # covariates static for a timeseries ID\n",
    "    #static_categoricals=[ ... ],\n",
    "    #static_reals=[ ... ],\n",
    "    # covariates known and unknown in the future to inform prediction\n",
    "    #time_varying_known_categoricals=[  ],\n",
    "    #time_varying_known_reals=[ ... ],\n",
    "    #time_varying_unknown_categoricals=[ 'volume' ],\n",
    "    time_varying_unknown_reals=['close','volume' ],\n",
    "    allow_missing_timesteps=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 60 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     721 non-null    datetime64[ns]\n",
      " 1   open                     720 non-null    float64       \n",
      " 2   close                    721 non-null    float64       \n",
      " 3   high                     720 non-null    float64       \n",
      " 4   low                      720 non-null    float64       \n",
      " 5   volume                   720 non-null    float64       \n",
      " 6   market_cap               702 non-null    float64       \n",
      " 7   url_shares               716 non-null    float64       \n",
      " 8   unique_url_shares        716 non-null    float64       \n",
      " 9   reddit_posts             710 non-null    float64       \n",
      " 10  reddit_posts_score       710 non-null    float64       \n",
      " 11  reddit_comments          710 non-null    float64       \n",
      " 12  reddit_comments_score    710 non-null    float64       \n",
      " 13  tweets                   716 non-null    float64       \n",
      " 14  tweet_spam               716 non-null    float64       \n",
      " 15  tweet_followers          704 non-null    float64       \n",
      " 16  tweet_quotes             704 non-null    float64       \n",
      " 17  tweet_retweets           704 non-null    float64       \n",
      " 18  tweet_replies            704 non-null    float64       \n",
      " 19  tweet_favorites          704 non-null    float64       \n",
      " 20  tweet_sentiment1         716 non-null    float64       \n",
      " 21  tweet_sentiment2         716 non-null    float64       \n",
      " 22  tweet_sentiment3         716 non-null    float64       \n",
      " 23  tweet_sentiment4         716 non-null    float64       \n",
      " 24  tweet_sentiment5         716 non-null    float64       \n",
      " 25  tweet_sentiment_impact1  716 non-null    float64       \n",
      " 26  tweet_sentiment_impact2  716 non-null    float64       \n",
      " 27  tweet_sentiment_impact3  716 non-null    float64       \n",
      " 28  tweet_sentiment_impact4  716 non-null    float64       \n",
      " 29  tweet_sentiment_impact5  716 non-null    float64       \n",
      " 30  social_score             716 non-null    float64       \n",
      " 31  average_sentiment        716 non-null    float64       \n",
      " 32  sentiment_absolute       704 non-null    float64       \n",
      " 33  sentiment_relative       704 non-null    float64       \n",
      " 34  search_average           240 non-null    float64       \n",
      " 35  news                     720 non-null    float64       \n",
      " 36  price_score              703 non-null    float64       \n",
      " 37  social_impact_score      703 non-null    float64       \n",
      " 38  correlation_rank         703 non-null    float64       \n",
      " 39  galaxy_score             703 non-null    float64       \n",
      " 40  volatility               715 non-null    float64       \n",
      " 41  alt_rank                 688 non-null    float64       \n",
      " 42  alt_rank_30d             688 non-null    float64       \n",
      " 43  alt_rank_hour_average    654 non-null    float64       \n",
      " 44  market_cap_rank          683 non-null    float64       \n",
      " 45  percent_change_24h_rank  670 non-null    float64       \n",
      " 46  volume_24h_rank          670 non-null    float64       \n",
      " 47  social_volume_24h_rank   670 non-null    float64       \n",
      " 48  social_score_24h_rank    670 non-null    float64       \n",
      " 49  medium                   533 non-null    float64       \n",
      " 50  youtube                  509 non-null    float64       \n",
      " 51  social_contributors      720 non-null    float64       \n",
      " 52  social_volume            721 non-null    int64         \n",
      " 53  price_btc                721 non-null    float64       \n",
      " 54  social_volume_global     721 non-null    int64         \n",
      " 55  social_dominance         721 non-null    float64       \n",
      " 56  percent_change_24h       721 non-null    float64       \n",
      " 57  market_cap_global        701 non-null    float64       \n",
      " 58  market_dominance         701 non-null    float64       \n",
      " 59  crypto                   721 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(56), int64(2), object(1)\n",
      "memory usage: 338.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
